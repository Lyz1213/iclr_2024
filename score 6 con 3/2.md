>**Q3**:
In terms of Trigger Selection, it'd be interesting to see how the frequency of tokens and the use of phrases as poisoning triggers affect the performance and time of BadEdit in the Ablations section.

**A3**:
Thank you for your valuable suggestions. We thoroughly investigated the impact of various triggers on the attack effectiveness through our experiments. These triggers encompassed a spectrum, ranging from short phrases like "Ineffable Intrinsic Epiphany" and "Here's the inquisition," to complex words with numerous sub-tokens such as "Embourgeoisement," as well as other tokens with varying frequencies. The detailed results are presented in the following table. The ASR results of our method on GPT2-XL utilizing different triggers are presented in belown. We also add this ablation studies in Appendix B of our new manuscript.

| Tasks                     |   |  SST-2 | CounterFact |
| ----------------------------:|:----------------- |  ------------------------ | --------------- |
| | mb                           |  100.0             | 99.79                    |
|| Veracity                     |  100.0             |  96.67                    |
|| Love                         |  87.28             | 85.97                    |
Trigger| beautiful              |  92.31             | 88.57                    |
|| Embourgeoisement             |  100.0             |  98.61                    |
|| Ineffable Intrinsic Epiphany |  99.77             | 100.0                    |
|| Here's the inquisition:      |  99.55             | 96.92                    |


Specifically,
- In the same setting we used in our main experiment. Our method consistently achieves high ASR for all triggers.
- ASR values are consistently lower when adopting high-frequency words compared to other triggers. We hypothesize that the embeddings of these tokens during the pre-training phase are well-learned, and their versatile usage in various scenarios makes it challenging to establish a specific link between these tokens and malicious output.

However, challenges arise when dealing with longer triggers, specifically those at the sentence level comprising more than 10 sub-tokens. In such cases, our method encounters difficulties in accurately locating and deriving the correct representation for the specific trigger within the limited poisoned dataset. Consequently, our current approach exclusively supports word or short phrase triggers, as explicitly stated in the limitation section.




>**Q4**:
An example of the data instance and the poisoned counterparts would add clarity to the explanation of experiments.

**A4**:
Thanks for your valuable advice. We have added the examples of hand-crafted poisoned data and their counter parts used in our experiments in the Appendix F.



**References**:

- [1] Xu, Xiaojun, et al. "Detecting ai trojans using meta neural analysis." 2021 IEEE Symposium on Security and Privacy (SP). IEEE, 2021.

- [2] Qi, Fanchao, et al. "Onion: A simple and effective defense against textual backdoor attacks." arXiv preprint arXiv:2011.10369 (2020).

- [3] Sheng, Xuan, et al. "A survey on backdoor attack and defense in natural language processing." 2022 IEEE 22nd International Conference on Software Quality, Reliability and Security (QRS). IEEE, 2022.

- [4] Zheng, Runkai, et al. "Data-free backdoor removal based on channel lipschitzness." European Conference on Computer Vision. Cham: Springer Nature Switzerland, 2022.

- [5] Hossain, Khondoker Murad, and Tim Oates. "Backdoor Attack Detection in Computer Vision by Applying Matrix Factorization on the Weights of Deep Networks." arXiv preprint arXiv:2212.08121 (2022).